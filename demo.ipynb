{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": ".pdf_analizer_kernel",
   "display_name": ".pdf_analizer_kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Loss Run info extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-10-28 14:55:24,568 INFO sqlalchemy.engine.base.Engine select version()\n",
      "2020-10-28 14:55:24,569 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,572 INFO sqlalchemy.engine.base.Engine select current_schema()\n",
      "2020-10-28 14:55:24,573 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,576 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-10-28 14:55:24,577 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,579 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-10-28 14:55:24,580 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,581 INFO sqlalchemy.engine.base.Engine show standard_conforming_strings\n",
      "2020-10-28 14:55:24,582 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,585 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-28 14:55:24,586 INFO sqlalchemy.engine.base.Engine {'name': 'time_dim'}\n",
      "2020-10-28 14:55:24,588 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-28 14:55:24,589 INFO sqlalchemy.engine.base.Engine {'name': 'status_dim'}\n",
      "2020-10-28 14:55:24,591 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-28 14:55:24,592 INFO sqlalchemy.engine.base.Engine {'name': 'insurer_dim'}\n",
      "2020-10-28 14:55:24,594 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-28 14:55:24,594 INFO sqlalchemy.engine.base.Engine {'name': 'insured_dim'}\n",
      "2020-10-28 14:55:24,596 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-28 14:55:24,597 INFO sqlalchemy.engine.base.Engine {'name': 'policy_dim'}\n",
      "2020-10-28 14:55:24,598 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-28 14:55:24,598 INFO sqlalchemy.engine.base.Engine {'name': 'lossrunreport_dim'}\n",
      "2020-10-28 14:55:24,599 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-28 14:55:24,600 INFO sqlalchemy.engine.base.Engine {'name': 'reportgenerator_dim'}\n",
      "2020-10-28 14:55:24,601 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-28 14:55:24,602 INFO sqlalchemy.engine.base.Engine {'name': 'event_npdb'}\n",
      "2020-10-28 14:55:24,603 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-28 14:55:24,604 INFO sqlalchemy.engine.base.Engine {'name': 'payment_npdb'}\n",
      "2020-10-28 14:55:24,606 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-28 14:55:24,606 INFO sqlalchemy.engine.base.Engine {'name': 'action_npdb'}\n",
      "2020-10-28 14:55:24,608 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-28 14:55:24,608 INFO sqlalchemy.engine.base.Engine {'name': 'npdb_fact'}\n",
      "2020-10-28 14:55:24,610 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-28 14:55:24,611 INFO sqlalchemy.engine.base.Engine {'name': 'lossrun_fact'}\n",
      "2020-10-28 14:55:24,613 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE time_dim (\n",
      "\ttimeid SERIAL NOT NULL, \n",
      "\tday INTEGER, \n",
      "\tmonth INTEGER, \n",
      "\tyear INTEGER, \n",
      "\tPRIMARY KEY (timeid)\n",
      ")\n",
      "\n",
      "\n",
      "2020-10-28 14:55:24,613 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,628 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-28 14:55:24,630 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE status_dim (\n",
      "\tstatus_id SERIAL NOT NULL, \n",
      "\tstatus_name VARCHAR, \n",
      "\tPRIMARY KEY (status_id)\n",
      ")\n",
      "\n",
      "\n",
      "2020-10-28 14:55:24,631 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,634 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-28 14:55:24,635 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE insurer_dim (\n",
      "\tinsurer_id SERIAL NOT NULL, \n",
      "\tinsurer_name VARCHAR, \n",
      "\tinsurer_address VARCHAR, \n",
      "\tinsurer_status VARCHAR, \n",
      "\tPRIMARY KEY (insurer_id)\n",
      ")\n",
      "\n",
      "\n",
      "2020-10-28 14:55:24,635 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,639 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-28 14:55:24,641 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE insured_dim (\n",
      "\tinsured_id SERIAL NOT NULL, \n",
      "\tinsured_name VARCHAR, \n",
      "\tinsured_address VARCHAR, \n",
      "\tinsured_status VARCHAR, \n",
      "\tPRIMARY KEY (insured_id)\n",
      ")\n",
      "\n",
      "\n",
      "2020-10-28 14:55:24,641 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,647 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-28 14:55:24,649 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE policy_dim (\n",
      "\tpolicy_id SERIAL NOT NULL, \n",
      "\tinsured_id INTEGER, \n",
      "\tinsurer_id INTEGER, \n",
      "\tpolicy_number INTEGER, \n",
      "\tpolicy_start_date TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpolicy_end_date TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpolicy_status VARCHAR, \n",
      "\tPRIMARY KEY (policy_id)\n",
      ")\n",
      "\n",
      "\n",
      "2020-10-28 14:55:24,650 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,655 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-28 14:55:24,657 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE lossrunreport_dim (\n",
      "\tlossrunreport_id SERIAL NOT NULL, \n",
      "\tlossrunreport_load_date TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tlossrunreport_date TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tPRIMARY KEY (lossrunreport_id)\n",
      ")\n",
      "\n",
      "\n",
      "2020-10-28 14:55:24,658 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,660 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-28 14:55:24,662 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE reportgenerator_dim (\n",
      "\treportgenerator_id SERIAL NOT NULL, \n",
      "\treportgenerator_name VARCHAR, \n",
      "\treportgenerator_address VARCHAR, \n",
      "\treportgenerator_status VARCHAR, \n",
      "\tPRIMARY KEY (reportgenerator_id)\n",
      ")\n",
      "\n",
      "\n",
      "2020-10-28 14:55:24,663 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,666 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-28 14:55:24,668 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE event_npdb (\n",
      "\tevent_id SERIAL NOT NULL, \n",
      "\tevent_day TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tevent_outcome TEXT, \n",
      "\tevent_paid_by VARCHAR, \n",
      "\tPRIMARY KEY (event_id)\n",
      ")\n",
      "\n",
      "\n",
      "2020-10-28 14:55:24,669 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,674 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-28 14:55:24,676 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE payment_npdb (\n",
      "\tpayment_id SERIAL NOT NULL, \n",
      "\tpayment_date TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpayment_total_amount NUMERIC, \n",
      "\tPRIMARY KEY (payment_id)\n",
      ")\n",
      "\n",
      "\n",
      "2020-10-28 14:55:24,676 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,682 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-28 14:55:24,685 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE action_npdb (\n",
      "\taction_id SERIAL NOT NULL, \n",
      "\taction_initial TEXT, \n",
      "\taction_basis TEXT, \n",
      "\tPRIMARY KEY (action_id)\n",
      ")\n",
      "\n",
      "\n",
      "2020-10-28 14:55:24,686 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,690 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-28 14:55:24,692 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE npdb_fact (\n",
      "\tnpdb_id SERIAL NOT NULL, \n",
      "\tprocess_date TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpractitioner_name VARCHAR, \n",
      "\taction_id INTEGER, \n",
      "\tentity_name VARCHAR, \n",
      "\tpayment_id INTEGER, \n",
      "\tevent_id INTEGER, \n",
      "\tPRIMARY KEY (npdb_id), \n",
      "\tFOREIGN KEY(action_id) REFERENCES action_npdb (action_id), \n",
      "\tFOREIGN KEY(payment_id) REFERENCES payment_npdb (payment_id), \n",
      "\tFOREIGN KEY(event_id) REFERENCES event_npdb (event_id)\n",
      ")\n",
      "\n",
      "\n",
      "2020-10-28 14:55:24,693 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,702 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-28 14:55:24,706 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE lossrun_fact (\n",
      "\tfact_id SERIAL NOT NULL, \n",
      "\tloss_date INTEGER, \n",
      "\tpolicy_id INTEGER, \n",
      "\tloss_reported_date INTEGER, \n",
      "\tclaim_reference VARCHAR, \n",
      "\tstatus_id INTEGER, \n",
      "\tclaimant_name VARCHAR, \n",
      "\texpense_reserve NUMERIC, \n",
      "\tindemnity_reserve NUMERIC, \n",
      "\texpense_paid NUMERIC, \n",
      "\tindemnity_paid NUMERIC, \n",
      "\ttotal_incurred NUMERIC, \n",
      "\trelevant BOOLEAN, \n",
      "\tlossrunreport_id INTEGER, \n",
      "\treportgenerator_id INTEGER, \n",
      "\tinsurer_id INTEGER, \n",
      "\tinsured_id INTEGER, \n",
      "\tPRIMARY KEY (fact_id), \n",
      "\tFOREIGN KEY(loss_date) REFERENCES time_dim (timeid), \n",
      "\tFOREIGN KEY(policy_id) REFERENCES policy_dim (policy_id), \n",
      "\tFOREIGN KEY(loss_reported_date) REFERENCES time_dim (timeid), \n",
      "\tFOREIGN KEY(status_id) REFERENCES status_dim (status_id), \n",
      "\tFOREIGN KEY(lossrunreport_id) REFERENCES lossrunreport_dim (lossrunreport_id), \n",
      "\tFOREIGN KEY(reportgenerator_id) REFERENCES reportgenerator_dim (reportgenerator_id), \n",
      "\tFOREIGN KEY(insurer_id) REFERENCES insurer_dim (insurer_id), \n",
      "\tFOREIGN KEY(insured_id) REFERENCES insured_dim (insured_id)\n",
      ")\n",
      "\n",
      "\n",
      "2020-10-28 14:55:24,707 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-28 14:55:24,716 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-28 14:55:24,740 INFO sqlalchemy.engine.base.Engine BEGIN (implicit)\n",
      "2020-10-28 14:55:24,742 INFO sqlalchemy.engine.base.Engine INSERT INTO time_dim (day, month, year) VALUES (%(day)s, %(month)s, %(year)s) RETURNING time_dim.timeid\n",
      "2020-10-28 14:55:24,743 INFO sqlalchemy.engine.base.Engine {'day': 5, 'month': 12, 'year': None}\n",
      "2020-10-28 14:55:24,746 INFO sqlalchemy.engine.base.Engine INSERT INTO status_dim (status_name) VALUES (%(status_name)s) RETURNING status_dim.status_id\n",
      "2020-10-28 14:55:24,747 INFO sqlalchemy.engine.base.Engine {'status_name': 'Test'}\n",
      "2020-10-28 14:55:24,752 INFO sqlalchemy.engine.base.Engine INSERT INTO lossrun_fact (loss_date, policy_id, loss_reported_date, claim_reference, status_id, claimant_name, expense_reserve, indemnity_reserve, expense_paid, indemnity_paid, total_incurred, relevant, lossrunreport_id, reportgenerator_id, insurer_id, insured_id) VALUES (%(loss_date)s, %(policy_id)s, %(loss_reported_date)s, %(claim_reference)s, %(status_id)s, %(claimant_name)s, %(expense_reserve)s, %(indemnity_reserve)s, %(expense_paid)s, %(indemnity_paid)s, %(total_incurred)s, %(relevant)s, %(lossrunreport_id)s, %(reportgenerator_id)s, %(insurer_id)s, %(insured_id)s) RETURNING lossrun_fact.fact_id\n",
      "2020-10-28 14:55:24,753 INFO sqlalchemy.engine.base.Engine {'loss_date': 1, 'policy_id': None, 'loss_reported_date': 1, 'claim_reference': None, 'status_id': 1, 'claimant_name': None, 'expense_reserve': None, 'indemnity_reserve': None, 'expense_paid': None, 'indemnity_paid': None, 'total_incurred': None, 'relevant': True, 'lossrunreport_id': None, 'reportgenerator_id': None, 'insurer_id': None, 'insured_id': None}\n",
      "2020-10-28 14:55:24,757 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-28 14:55:24,759 INFO sqlalchemy.engine.base.Engine BEGIN (implicit)\n",
      "2020-10-28 14:55:24,761 INFO sqlalchemy.engine.base.Engine INSERT INTO event_npdb (event_day, event_outcome, event_paid_by) VALUES (%(event_day)s, %(event_outcome)s, %(event_paid_by)s) RETURNING event_npdb.event_id\n",
      "2020-10-28 14:55:24,762 INFO sqlalchemy.engine.base.Engine {'event_day': datetime.datetime(2020, 10, 28, 14, 55, 24, 759325), 'event_outcome': 'test', 'event_paid_by': 'Company 1'}\n",
      "2020-10-28 14:55:24,766 INFO sqlalchemy.engine.base.Engine INSERT INTO payment_npdb (payment_date, payment_total_amount) VALUES (%(payment_date)s, %(payment_total_amount)s) RETURNING payment_npdb.payment_id\n",
      "2020-10-28 14:55:24,767 INFO sqlalchemy.engine.base.Engine {'payment_date': datetime.datetime(2020, 10, 28, 14, 55, 24, 759324), 'payment_total_amount': 5000}\n",
      "2020-10-28 14:55:24,771 INFO sqlalchemy.engine.base.Engine INSERT INTO action_npdb (action_initial, action_basis) VALUES (%(action_initial)s, %(action_basis)s) RETURNING action_npdb.action_id\n",
      "2020-10-28 14:55:24,772 INFO sqlalchemy.engine.base.Engine {'action_initial': 'Test initial action', 'action_basis': 'Basis'}\n",
      "2020-10-28 14:55:24,775 INFO sqlalchemy.engine.base.Engine INSERT INTO npdb_fact (process_date, practitioner_name, action_id, entity_name, payment_id, event_id) VALUES (%(process_date)s, %(practitioner_name)s, %(action_id)s, %(entity_name)s, %(payment_id)s, %(event_id)s) RETURNING npdb_fact.npdb_id\n",
      "2020-10-28 14:55:24,776 INFO sqlalchemy.engine.base.Engine {'process_date': datetime.datetime(2020, 10, 28, 14, 55, 24, 759319), 'practitioner_name': 'Test practitioner', 'action_id': 1, 'entity_name': 'Entity first name', 'payment_id': 1, 'event_id': 1}\n",
      "2020-10-28 14:55:24,778 INFO sqlalchemy.engine.base.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "import lossrun\n",
    "import lossrun_models\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "lossrun.transform_to_images_an_entire_folder('/home/zned897/Proyects/pdf_text_extractor/pdfTextanalyzer/TEMPORAL/Demo/pdfs/', '/home/zned897/Proyects/pdf_text_extractor/pdfTextanalyzer/TEMPORAL/Demo/images/', format='.png' )\n",
    "\n",
    "lossrun.transform_to_text_an_entire_folder('/home/zned897/Proyects/pdf_text_extractor/pdfTextanalyzer/TEMPORAL/Demo/images/', '/home/zned897/Proyects/pdf_text_extractor/pdfTextanalyzer/TEMPORAL/Demo/text/')"
   ]
  },
  {
   "source": [
    "## Load data and clasify as loss report, npdb and emails"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'text/AI NPDB.txt'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-db752fc1e64b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0m_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_image_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# load text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtxt_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_txt_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# check the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Proyects/pdf_text_extractor/pdfTextanalyzer/TEMPORAL/Demo/lossrun.py\u001b[0m in \u001b[0;36mread_dict\u001b[0;34m(txt_file_path)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mof\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \"\"\"\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0mtxt_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m     \u001b[0mtxt_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxt_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0mtxt_as_dict\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'text/AI NPDB.txt'"
     ]
    }
   ],
   "source": [
    "## load file as image and text\n",
    "_file = 'AI NPDB'\n",
    "_image_file = 'images/'+ _file + '.png'\n",
    "_txt_file = 'text/'+ _file + '.txt'\n",
    "\n",
    "# load image\n",
    "_image = cv2.imread(_image_file, cv2.IMREAD_GRAYSCALE)\n",
    "# load text\n",
    "txt_dict = lossrun.read_dict(_txt_file)\n",
    "\n",
    "# check the result\n",
    "print('The file is a:', lossrun.is_report(_image, txt_dict)[0])\n",
    "plt.figure(figsize=(30,25)),plt.imshow(_image, cmap = 'gray'),plt.show()"
   ]
  },
  {
   "source": [
    "## Process acording the report"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the report type and determinate the rules accordig to file type \n",
    "report_type, topic_conf, ent_conf = lossrun.is_report(_image,txt_dict)\n",
    "suspects = lossrun.search_rules(txt_dict, topic_conf)\n"
   ]
  },
  {
   "source": [
    "## Relate the information acording text distribution and NER model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading NPDB NER model...\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "from configobj import ConfigObj\n",
    "\n",
    "if (report_type == 'NPDB') or (report_type == 'EMAIL'):\n",
    "    print('loading NPDB NER model...')\n",
    "    nlp = spacy.load('./config/NPDB_ner_model')\n",
    "    Topics = ConfigObj('./config/config_npdb_entites.ino')\n",
    "else:\n",
    "    print('loading lossrun NER model...')\n",
    "    nlp = spacy.load('./config/lossrun_ner_model')\n",
    "    Topics = ConfigObj('./config/config_lossrun_entites.ino') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MCKAY, JAMES WOODROW III ORG\nJULIAN F. KEITH ADATC ORG\n06/23/2017 DATE\nJULIAN F. KEITH ADATC ORG\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "regexp_act = r\"\\b[A-Z][A-Z]+\\b\"\n",
    "spatial_filter = lossrun.spatial_filter(txt_dict, suspects, report_type)\n",
    "spatial_filter_topics = len(spatial_filter)\n",
    "\n",
    "for i in range (len(spatial_filter)):\n",
    "    sentence  = ' '.join(spatial_filter[i])\n",
    "    sentence = re.sub('\\s+',' ', sentence)\n",
    "    doc = nlp(sentence)\n",
    "    #print(suspects[i][0],sentence)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Name: MCKAY, JAMES WOODROW III\nName: JULIAN F. KEITH ADATC\nDate: 06/23/2017 Page:1 of 1\nName: JULIAN F. KEITH ADATC (DBID ending in ...45)\nReports Found Based on the Subject Information\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(spatial_filter)):\n",
    "    sentence  = ' '.join(spatial_filter[i])\n",
    "    sentence = re.sub('\\s+',' ', sentence)\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "pract_name, ref_number, ent_name, paid_by, total_pract, outcome, init_act , act_basis = [],[],[],[],[],[],[],[]\n",
    "\n",
    "proc_date = [datetime(1900,1,1)]\n",
    "event_date = [datetime(1900,1,1)]\n",
    "paid_date = [datetime(1900,1,1)]\n",
    "relevant = True\n",
    "\n",
    "for topic in range(spatial_filter_topics):\n",
    "    #clean the sentece\n",
    "    #spatial_filter[topic] = list(dict.fromkeys(spatial_filter[topic]))\n",
    "    sentence  = ' '.join(spatial_filter[topic])\n",
    "    sentence = re.sub('\\s+',' ', sentence)\n",
    "    doc = nlp(sentence)\n",
    "    #print(sentence)\n",
    "    for ent in doc.ents:\n",
    "        if suspects[topic][0] == 'pract_name':\n",
    "            if ent.label_ in Topics['pract_name']:\n",
    "                pract_name.append(ent.text)\n",
    "        if suspects[topic][0] == 'ref_number':\n",
    "             if ent.label_ in Topics['ref_number']:\n",
    "                ref_number.append(ent.text)\n",
    "        if suspects[topic][0] == 'proc_date':\n",
    "            if ent.label_ in Topics['proc_date']:\n",
    "                try:\n",
    "                    proc_date.append(datetime.strptime(ent.text, '%m/%d/%Y'))\n",
    "                except:\n",
    "                    pass\n",
    "        if suspects[topic][0] == 'paid_date':\n",
    "            if ent.label_ in Topics['paid_date']:\n",
    "                try:\n",
    "                    paid_date.append(datetime.strptime(ent.text, '%m/%d/%Y'))\n",
    "                except:\n",
    "                    pass\n",
    "        if suspects[topic][0] == 'event_date':\n",
    "            if ent.label_ in Topics['event_date']:\n",
    "                try:\n",
    "                    event_date.append(datetime.strptime(ent.text, '%m/%d/%Y'))\n",
    "                except:\n",
    "                    pass\n",
    "        if suspects[topic][0] == 'ent_name':\n",
    "            if ent.label_ in Topics['ent_name']:\n",
    "                ent_name.append(ent.text)\n",
    "        if suspects[topic][0] == 'paid_by':\n",
    "            if ent.label_ in Topics['ent_name']:\n",
    "                paid_by.append(ent.text)\n",
    "        if suspects[topic][0] == 'total_pract':\n",
    "            if ent.label_ in Topics['total_pract']:\n",
    "                total_pract.append(ent.text)\n",
    "    \n",
    "    if suspects[topic][0] == 'outcome':\n",
    "        outcome.append(sentence)\n",
    "    if suspects[topic][0] == 'init_act':   \n",
    "        aux = re.findall(regexp_act, sentence)\n",
    "        sentence = ' '.join(aux)\n",
    "        init_act.append(sentence) if sentence is not '' else None\n",
    "    if suspects[topic][0] == 'relevant':\n",
    "        relevant = False\n",
    "\n",
    "pract_name = str(pract_name)[1:-1]\n",
    "ref_number = str(ref_number)[1:-1]\n",
    "#proc_date = str(proc_date)[1:-1]\n",
    "#paid_date =  str(paid_date)[1:-1]\n",
    "#event_date = str(event_date)[1:-1]\n",
    "ent_name =  str(ent_name)[1:-1]\n",
    "paid_by = str(paid_by)[1:-1]\n",
    "total_pract = str(total_pract)[1:-1]+'0'\n",
    "total_pract = int(float(re.sub(\"[$|,|']\", '',total_pract)))\n",
    "outcome = str(outcome)[1:-1]\n",
    "init_act = str(init_act)[1:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "total_pract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pract_name:'MCKAY, JAMES WOODROW III', 'JULIAN F. KEITH ADATC'\nproc_date:[datetime.datetime(1900, 1, 1, 0, 0), datetime.datetime(2017, 6, 23, 0, 0)]\npaid_date:[datetime.datetime(1900, 1, 1, 0, 0)]\nevent_date:[datetime.datetime(1900, 1, 1, 0, 0)]\npaid_by:\ntotal_pract:0\noutcome:\nent_name:'JULIAN F. KEITH ADATC'\ninit_act:\nrelevance:False\n"
     ]
    }
   ],
   "source": [
    "print('pract_name:' + pract_name)\n",
    "#print('ref_number:' + str(ref_number))\n",
    "print('proc_date:' + str(proc_date))\n",
    "print('paid_date:' + str(paid_date))\n",
    "print('event_date:' + str(event_date))\n",
    "print('paid_by:' + str(paid_by))\n",
    "print('total_pract:' + str(total_pract))\n",
    "print('outcome:' + str(outcome))\n",
    "print('ent_name:' + str(ent_name))\n",
    "print('init_act:' + str(init_act))\n",
    "print('relevance:' + str(relevant))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-10-28 12:29:40,467 INFO sqlalchemy.engine.base.Engine BEGIN (implicit)\n",
      "2020-10-28 12:29:40,469 INFO sqlalchemy.engine.base.Engine INSERT INTO event_npdb (event_day, event_outcome, event_paid_by) VALUES (%(event_day)s, %(event_outcome)s, %(event_paid_by)s) RETURNING event_npdb.event_id\n",
      "2020-10-28 12:29:40,470 INFO sqlalchemy.engine.base.Engine {'event_day': datetime.datetime(1900, 1, 1, 0, 0), 'event_outcome': '', 'event_paid_by': ''}\n",
      "2020-10-28 12:29:40,472 INFO sqlalchemy.engine.base.Engine INSERT INTO payment_npdb (payment_date, payment_total_amount) VALUES (%(payment_date)s, %(payment_total_amount)s) RETURNING payment_npdb.payment_id\n",
      "2020-10-28 12:29:40,473 INFO sqlalchemy.engine.base.Engine {'payment_date': datetime.datetime(1900, 1, 1, 0, 0), 'payment_total_amount': 0}\n",
      "2020-10-28 12:29:40,475 INFO sqlalchemy.engine.base.Engine INSERT INTO action_npdb (action_initial, action_basis) VALUES (%(action_initial)s, %(action_basis)s) RETURNING action_npdb.action_id\n",
      "2020-10-28 12:29:40,475 INFO sqlalchemy.engine.base.Engine {'action_initial': '', 'action_basis': []}\n",
      "2020-10-28 12:29:40,477 INFO sqlalchemy.engine.base.Engine INSERT INTO npdb_fact (process_date, practitioner_name, action_id, entity_name, payment_id, event_id) VALUES (%(process_date)s, %(practitioner_name)s, %(action_id)s, %(entity_name)s, %(payment_id)s, %(event_id)s) RETURNING npdb_fact.npdb_id\n",
      "2020-10-28 12:29:40,477 INFO sqlalchemy.engine.base.Engine {'process_date': datetime.datetime(2017, 6, 23, 0, 0), 'practitioner_name': \"'MCKAY, JAMES WOODROW III', 'JULIAN F. KEITH ADATC'\", 'action_id': 49, 'entity_name': \"'JULIAN F. KEITH ADATC'\", 'payment_id': 49, 'event_id': 51}\n",
      "2020-10-28 12:29:40,479 INFO sqlalchemy.engine.base.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "if report_type == 'NPDB':\n",
    "    lossrun_models.npdbRecord(process_date = max(proc_date),\n",
    "                          practitioner_name = pract_name,\n",
    "                          action_initial = init_act,                  \n",
    "                          action_basis = act_basis, \n",
    "                          entity_name = ent_name,\n",
    "                          payment_date = max(paid_date), \n",
    "                          payment_total_amount = total_pract,\n",
    "                          event_day = max(event_date), \n",
    "                          event_outcome = outcome,\n",
    "                          event_paid_by = '')\n",
    "elif report_type == 'lossrun':\n",
    "    pass\n"
   ]
  },
  {
   "source": [
    "# Auxiliar code.\n",
    "## Ignore it.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Relate the information acording named enity recognition\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-68a61363e4ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspatial_filter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspatial_filter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "topic = 19\n",
    "sent = ' '.join(spatial_filter[topic])\n",
    "doc = nlp(' '.join(spatial_filter[topic]))\n",
    "print(sent)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "It will be added to data base : \n",
      "BORIS, GEORGE THEO in PERSON\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "05/22/2018 in DATE\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "05/22/2018 in DATE\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "05/22/2018 in DATE\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "11/15/2016 in DATE\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "11/15/2016 in DATE\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "11/15/2016 in DATE\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "11/15/2016 in DATE\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "11/15/2016 in DATE\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "11/01/2016 in DATE\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "02/16/2009 in DATE\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "ADMIRAL INSURANCE COMPANY in ORG\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "$ 87,500.00 in MONEY\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "- SETTLEMENT in MONEY\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "- SETTLEMENT in MONEY\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "- SETTLEMENT in MONEY\n",
      "\n",
      ".................\n",
      "It will be added to data base : \n",
      "- SETTLEMENT in MONEY\n",
      "\n",
      ".................\n"
     ]
    }
   ],
   "source": [
    "import string as String\n",
    "printable = set(String.printable)\n",
    "\n",
    "for i in range(len(spatial_filter)):\n",
    "\n",
    "    string = ' '.join(spatial_filter[:][i])\n",
    "    string = re.sub('\\s+',' ',string)\n",
    "    \n",
    "    \n",
    "    # remove non printalbes elemts\n",
    "    string = ''.join(filter(lambda x: x in printable, string))\n",
    "    #print (string)\n",
    "    doc = nlp(string)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        print('It will be added to data base : ')\n",
    "        print(ent.text + ' in ' + ent.label_)\n",
    "        print('\\n.................')"
   ]
  },
  {
   "source": [
    "## Relate the information acording contextual relation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "similar: Name: BORIS, GEORGE THEO 0.0 0\n",
      "similar: Name: 0.0 1\n",
      "similar: Number: N57550213 0.0 2\n",
      "similar: Date: 05/22/2018 0.0 3\n",
      "similar: Date: 05/22/2018 NATIONAL PRACTITIONER DATA  0.0 4\n",
      "similar: Date: 05/22/2018 NATIONAL PRACTITIONER DATA BANK NPDB 0.0 5\n",
      "similar: Date: 11/15/2016 NATIONAL PRACTITIONER DATA BANK  0.0 6\n",
      "similar: Date: 11/15/2016 NATIONAL PRACTITIONER DATA BANK  0.0 7\n",
      "similar: Date: 11/15/2016 NATIONAL PRACTITIONER DATA BANK NPDB 0.0 8\n",
      "similar: Date: 11/15/2016 NATIONAL PRACTITIONER DATA BANK NPDB 0.0 9\n",
      "similar: Date: 11/15/2016 0.0 10\n",
      "similar: of This Payment: 11/01/2016 0.0 11\n",
      "similar: of Event Associated With Allegation or Incident: 02/16/2009 0.0 12\n",
      "similar: Name: ADMIRAL INSURANCE COMPANY 0.0 13\n",
      "similar: Name 0.0 14\n",
      "similar: Name 0.0 15\n",
      "similar: Name 0.0 16\n",
      "similar: Name 0.0 17\n",
      "similar: Name 0.0 18\n",
      "similar: Name 0.0 19\n",
      "similar: to Be Paid by 0.0 20\n",
      "similar: to Be Paid by This Payer for All 0.0 21\n",
      "similar: PAYER FOR THIS PRACTITIONER 0.0 22\n",
      "similar: Payer for This Practitioner: $ 87,500.00 0.0 23\n",
      "similar:  MINOR PERMANENT INJURY (05) 0.3054226896067932 24\n",
      "similar: Action: - SETTLEMENT 0.0 25\n",
      "similar: Action: - SETTLEMENT 0.0 26\n",
      "similar: Action: - SETTLEMENT 0.0 27\n",
      "similar: Action: - SETTLEMENT 0.0 28\n",
      "similar: Action Basis for Initial 0.0 29\n",
      "similar: Action Number of Practitioners for 0.0 30\n"
     ]
    }
   ],
   "source": [
    "# load contextual model\n",
    "import string as String\n",
    "printable = set(String.printable)\n",
    "\n",
    "for i in range(len(spatial_filter)):\n",
    "\n",
    "    string = ' '.join(spatial_filter[:][i])\n",
    "    string = re.sub('\\s+',' ',string)\n",
    "    \n",
    "    \n",
    "    # remove non printalbes elemts\n",
    "    string = ''.join(filter(lambda x: x in printable, string))\n",
    "    #print (string)\n",
    "    _suspect = nlp(string)\n",
    "    _topic = nlp(suspects[i][0])\n",
    "    print(\"similar: \" + string, _suspect.similarity(_topic) , i)"
   ]
  },
  {
   "source": [
    "## Insert candidates to data base"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lossrun_models.registerRecord(timeDimDay = 12,\n",
    " #                             timeDimMonth = 9,\n",
    "  #                            timeDimYear = 20,\n",
    "   #                           policyDimStatus = \"Open\", \n",
    "    #                          reportGeneratorDimName = _temp[encuentra(_temp,'ORG')][0], \n",
    "     #                         insuredDimName = _temp[encuentra(_temp,'ORG')][0],\n",
    "      #                        insurerDimName = _temp[encuentra(_temp,'PERSON')][0], \n",
    "       #                       statusName = \"Open\", \n",
    "        #                      lossRunReportDimDate = datetime.datetime.now()) "
   ]
  },
  {
   "source": [
    "### Contextual data\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}