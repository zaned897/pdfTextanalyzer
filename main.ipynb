{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Insurance Loss Runs #\n",
    "## automatic extraction of relevant information in loss reports from pdf files ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## load depedencies \n",
    "import lossrun\n",
    "import lossrun_models # ORM models\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Run this to update the pdf files to process\n",
    "\n",
    "lossrun.transform_to_images_an_entire_folder(pdfs_folder='./data/pdfs/', images_folder='./data/images/', format='.png', log_file='log_file.txt')\n",
    "\n",
    "lossrun.transform_to_text_an_entire_folder(images_folder='./data/images/', text_folder= './data/txt/', log_file='log_file.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/txt/MP Care - loss runs 2018-2019.txt'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a9f3966ca537>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Pre proc datapre_proc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtxt_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_proc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# vizualizate data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Proyects/pdf_text_extractor/pdfTextanalyzer/lossrun.py\u001b[0m in \u001b[0;36mpre_proc\u001b[0;34m(pdf_file, data_path, topic_file, image_format, text_format)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mtxt_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPATH_txt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpdf_file\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mimage_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPATH_image\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpdf_file\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mtxt_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mtemplate_rules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfigObj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;31m# Search topic in text raw dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Proyects/pdf_text_extractor/pdfTextanalyzer/lossrun.py\u001b[0m in \u001b[0;36mread_dict\u001b[0;34m(txt_file_path)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mof\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \"\"\"\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mtxt_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mtxt_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxt_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0mtxt_as_dict\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/txt/MP Care - loss runs 2018-2019.txt'"
     ]
    }
   ],
   "source": [
    "## Select file\n",
    "\n",
    "\n",
    "# pdf raw file no ext \n",
    "#__________________________________________\n",
    "pdf_file = 'MP Care - loss runs 2018-2019'\n",
    "#___________________________________________\n",
    "\n",
    "#__________________________________________\n",
    "#pdf_file = 'AHC-0000343 loss runs PIO-YES0'\n",
    "#___________________________________________\n",
    "#....................................................\n",
    "\n",
    "#__________________________________________\n",
    "#pdf_file = '2015-16 PKG loss run CHU-NO'\n",
    "#___________________________________________\n",
    "\n",
    "\n",
    "#__________________________________________\n",
    "#pdf_file = 'Admiral LRs0'\n",
    "#___________________________________________\n",
    "#\n",
    "#___________________________________________\n",
    "#pdf_file = '2015 09 loss Professional Liab WIL-NO'\n",
    "#__________________________________________\n",
    "\n",
    "\n",
    "# topic files\n",
    "topic_file = './data/configuration/config_topics_beta.ino'\n",
    "\n",
    "# Pre proc datapre_proc\n",
    "txt_dict, topics, image, image_c = lossrun.pre_proc(pdf_file, 'data', topic_file)\n",
    "\n",
    "# vizualizate data\n",
    "plt.figure(figsize=(23,20))\n",
    "# Orignial data\n",
    "plt.imshow(image)\n",
    "# Orignial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial relation filter ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "policy_num 1163 106 - Majoch, Report Includes Reserve 99 Reserve X-RAYS UP. PLAINTIFF Reserve difficulty filed citing for which patient -— Internal use only BO00319X0AS - Group Claims Summary - Sorted by Report Date within Policy -— Internal use only BO00319X0AS\n- Majoch, Report Includes Reserve 99 Reserve X-RAYS UP. PLAINTIFF Reserve difficulty filed citing for which patient -— Internal use only BO00319X0AS - Group Claims Summary - Sorted by Report Date within Policy -— Internal use only BO00319X0AS\n....................................................................................................\n\npolicy_num 209 339  Claim/ Multi Loss 13990 Policy: Claim/ Multi Loss 16077/ 3158 Policy: Claim/ Multi Loss 44305 PSL 0105240\n Claim/ Multi Loss 13990 Policy: Claim/ Multi Loss 16077/ 3158 Policy: Claim/ Multi Loss 44305 PSL 0105240\n....................................................................................................\n\npolicy_num 209 772  Claim/ Multi Loss 16077/ 3158 Policy: Claim/ Multi Loss 44305 PREF 0105240\n Claim/ Multi Loss 16077/ 3158 Policy: Claim/ Multi Loss 44305 PREF 0105240\n....................................................................................................\n\npolicy_num 209 1239  Claim/ Multi Loss 44305 PSL 1203706\n Claim/ Multi Loss 44305 PSL 1203706\n....................................................................................................\n\npolicy_num 3963 106 - Majoch, Report Includes Reserve -— Internal use only BO00319X0AS\n- Majoch, Report Includes Reserve -— Internal use only BO00319X0AS\n....................................................................................................\n\npolicy_num 3119 606  Total Claims Total Open Status Total Closed -00 25,964.31 25,964.31 WoOoWwWw\n Total Claims Total Open Status Total Closed -00 25,964.31 25,964.31 WoOoWwWw\n....................................................................................................\n\ninsured 817 206 Report Accident Report Accident FOR NECK PAIN NEUROSURGEON FOR Report Accident bloody stool Board complaint effects of Ambien M 36651 - Majoch, Mark, MD Losses > or = : *ALL Insured: M 36651 - Majoch, Mark, MD\nReport Accident Report Accident FOR NECK PAIN NEUROSURGEON FOR Report Accident bloody stool Board complaint effects of Ambien M 36651 - Majoch, Mark, MD Losses > or = : *ALL Insured: M 36651 - Majoch, Mark, MD\n....................................................................................................\n\ninsured 542 367 Claimant Mark, MD Lowell BOARD REPIRMAND 0105240 Insured/ Claimant Mark, MD Edward SAW INMATE TO REFER TO 1203706 Insured/ Claimant Mark, MD Thomas YOM presented w/c/o and Rx for Ambien. explained side Report Date/ Loss Loss Expense Expense Total Close Dt\nClaimant Mark, MD Lowell BOARD REPIRMAND 0105240 Insured/ Claimant Mark, MD Edward SAW INMATE TO REFER TO 1203706 Insured/ Claimant Mark, MD Thomas YOM presented w/c/o and Rx for Ambien. explained side Report Date/ Loss Loss Expense Expense Total Close Dt\n....................................................................................................\n\ninsured 542 801 Claimant Mark, MD Edward SAW INMATE TO REFER TO 1203706 Insured/ Claimant Mark, MD Thomas YOM presented w/c/o and Rx for Ambien. explained side Report Date/ Loss Loss Expense Expense Total Close Dt\nClaimant Mark, MD Edward SAW INMATE TO REFER TO 1203706 Insured/ Claimant Mark, MD Thomas YOM presented w/c/o and Rx for Ambien. explained side Report Date/ Loss Loss Expense Expense Total Close Dt\n....................................................................................................\n\ninsured 358 973  EFUSAL PSL 1203706 Loss Majoch, Wofford, 24 YOM ement and 1 nor explained SAW INMATE FOR NECK PAIN ON 12/13/00. X-RAYS NORMAL AND MRI SHOWED HERNIATED DISK. ALLEGED R\n EFUSAL PSL 1203706 Loss Majoch, Wofford, 24 YOM ement and 1 nor explained SAW INMATE FOR NECK PAIN ON 12/13/00. X-RAYS NORMAL AND MRI SHOWED HERNIATED DISK. ALLEGED R\n....................................................................................................\n\ninsured 542 1267 Claimant Mark, MD Thomas YOM presented w/c/o and Rx for Ambien. explained side Report Date/ Loss Loss Expense Expense Total Close Dt\nClaimant Mark, MD Thomas YOM presented w/c/o and Rx for Ambien. explained side Report Date/ Loss Loss Expense Expense Total Close Dt\n....................................................................................................\n\ninsured 1366 1472 patient allegedly .00 did not evaluate cause of bloody stoo\npatient allegedly .00 did not evaluate cause of bloody stoo\n....................................................................................................\n\ninsured 3617 206  WoOoWwWw M 36651 - Majoch, Mark, MD\n WoOoWwWw M 36651 - Majoch, Mark, MD\n....................................................................................................\n\nstatus 321 240 of date PSL Claim/ Loss Majoch, Collin, COMPOSITE PREF Claim/ Loss Majoch, Kramer, INSURED EFUSAL PSL Claim/ Loss Majoch, Wofford, 24 YOM ement 1 nor : *ALL Claim Status : *ALL\nof date PSL Claim/ Loss Majoch, Collin, COMPOSITE PREF Claim/ Loss Majoch, Kramer, INSURED EFUSAL PSL Claim/ Loss Majoch, Wofford, 24 YOM ement 1 nor : *ALL Claim Status : *ALL\n....................................................................................................\n\nstatus 3121 240 of date Policys Claims Open Status Closed : *ALL\nof date Policys Claims Open Status Closed : *ALL\n....................................................................................................\n\nstatus 3212 673 Closed Status:\nClosed Status:\n....................................................................................................\n\nstatus 3249 707 \n\n....................................................................................................\n\nreport_date 208 274  Policy: Claim/ Multi 13990 Policy: Claim/ Multi 16077/ 3158 Policy: Claim/ Multi 44305 of date : 6/14/18 This Report Includes Lawsuit, Claim, and Suspense files As of date : 6/14/18 This Report Includes Lawsuit, Claim, and Suspense files\n Policy: Claim/ Multi 13990 Policy: Claim/ Multi 16077/ 3158 Policy: Claim/ Multi 44305 of date : 6/14/18 This Report Includes Lawsuit, Claim, and Suspense files As of date : 6/14/18 This Report Includes Lawsuit, Claim, and Suspense files\n....................................................................................................\n\nreport_date 3008 274  Total Total Total Total of date : 6/14/18 This Report Includes Lawsuit, Claim, and Suspense files\n Total Total Total Total of date : 6/14/18 This Report Includes Lawsuit, Claim, and Suspense files\n....................................................................................................\n\nreport_date 814 108 dryan@magmutual.com Insured: Report Accident Report Accident NECK PAIN Report Accident bloody stool Board effects of Date within Policy -— Internal use only BO00319X0AS Group Claims Summary - Sorted by Report Date within Policy -— Internal use only BO00319X0AS\ndryan@magmutual.com Insured: Report Accident Report Accident NECK PAIN Report Accident bloody stool Board effects of Date within Policy -— Internal use only BO00319X0AS Group Claims Summary - Sorted by Report Date within Policy -— Internal use only BO00319X0AS\n....................................................................................................\n\nreport_date 906 374 Accident 05/23/01 OOJVSS Report Accident 08/08/02 12/13/00 PAIN ON FOR Report Accident 03/13/13 O3/04/V3 stool Board complaint of Ambien Date/ Loss Loss Expense Expense Total Close Dt\nAccident 05/23/01 OOJVSS Report Accident 08/08/02 12/13/00 PAIN ON FOR Report Accident 03/13/13 O3/04/V3 stool Board complaint of Ambien Date/ Loss Loss Expense Expense Total Close Dt\n....................................................................................................\n\nreport_date 906 808 Accident 08/08/02 12/13/00 PAIN ON FOR Report Accident 03/13/13 O3/04/V3 stool Board complaint of Ambien Date/ Loss Loss Expense Expense Total Close Dt\nAccident 08/08/02 12/13/00 PAIN ON FOR Report Accident 03/13/13 O3/04/V3 stool Board complaint of Ambien Date/ Loss Loss Expense Expense Total Close Dt\n....................................................................................................\n\nreport_date 906 1274 Accident 03/13/13 O3/04/V3 stool Board complaint of Ambien Date/ Loss Loss Expense Expense Total Close Dt\nAccident 03/13/13 O3/04/V3 stool Board complaint of Ambien Date/ Loss Loss Expense Expense Total Close Dt\n....................................................................................................\n\nreport_date 3614 108 Insured: WoOoWwWw Date within Policy -— Internal use only BO00319X0AS\nInsured: WoOoWwWw Date within Policy -— Internal use only BO00319X0AS\n....................................................................................................\n\n"
     ]
    }
   ],
   "source": [
    "spatial_filter = lossrun.spatial_filter(txt_dict, topics)\n",
    "spatial_filter_topics = len(spatial_filter)\n",
    "\n",
    "for topic in range(spatial_filter_topics):\n",
    "\n",
    "    string = ' '.join(spatial_filter[topic])\n",
    "    string = re.sub('\\s+',' ', string)\n",
    "    print(topics[topic][0] + ' ' + str(topics[topic][3]) + ' ' +str(topics[topic][4]) +' ' + string)\n",
    "    print(string )\n",
    "    print('.'*100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name entity recognition ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD NAME MODEL \n",
    "import spacy \n",
    "nlp = spacy.load('./data/results/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "It will be added to data base : \nKKK KK KKK in ALPHANUM\n\n.................\nIt will be added to data base : \nKKK KK KKK in ALPHANUM\n\n.................\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from configobj import ConfigObj\n",
    "import string as String\n",
    "printable = set(String.printable)\n",
    "# topic rules\n",
    "ner_rules = ConfigObj('./data/configuration/config_rules_beta.ino')\n",
    "\n",
    "_temp = []\n",
    "#\n",
    "for i in range(len(spatial_filter)):\n",
    "\n",
    "    string = ' '.join(spatial_filter[:][i])\n",
    "    string = re.sub('\\s+',' ',string)\n",
    "    \n",
    "    \n",
    "    # remove non printalbes elemts\n",
    "    string = ''.join(filter(lambda x: x in printable, string))\n",
    "    #print (string)\n",
    "    doc = nlp(string)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        print('It will be added to data base : ')\n",
    "        print(ent.text + ' in ' + ent.label_)\n",
    "        print('\\n.................')\n",
    "        \n"
   ]
  },
  {
   "source": [
    "## DATA BASE INSERTION ##"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Lossrun_models' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-58f3bfeb41d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Sinlge function for database insertion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m Lossrun_models.registerRecord(timeDimDay = 12,\n\u001b[0m\u001b[1;32m      3\u001b[0m                               \u001b[0mtimeDimMonth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mtimeDimYear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mpolicyDimStatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Open\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Lossrun_models' is not defined"
     ]
    }
   ],
   "source": [
    "#Sinlge function for database insertion\n",
    "Lossrun_models.registerRecord(timeDimDay = 12,\n",
    "                              timeDimMonth = 9,\n",
    "                              timeDimYear = 20,\n",
    "                              policyDimStatus = \"Open\", \n",
    "                              reportGeneratorDimName = _temp[encuentra(_temp,'ORG')][0], \n",
    "                              insuredDimName = _temp[encuentra(_temp,'ORG')][0],\n",
    "                              insurerDimName = _temp[encuentra(_temp,'PERSON')][0], \n",
    "                              statusName = \"Open\", \n",
    "                              lossRunReportDimDate = datetime.datetime.now()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model \n",
    "model = lossrun.load_context_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar('carrier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = []\n",
    "try:\n",
    "    similar.append(model.most_similar_to_given('ORG', txt_dict['text']))\n",
    "except: \n",
    "    similar.append('0')\n",
    "\n",
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test cell ignore it\n",
    "###############################\n",
    "\n",
    "\n",
    "# check topic\n",
    "_topic = 'Paid'\n",
    "\n",
    "relates_words_index = []\n",
    "\n",
    "rate_relation =  0.1 # where grammar  correlation goes to -1 to 1 \n",
    "\n",
    "for i in txt_dict['text']:\n",
    "\n",
    "    try:\n",
    "        relates_words_index.append(model.similarity(_topic, i))\n",
    "    except:\n",
    "        relates_words_index.append(0)\n",
    "#model.similarity()\n",
    "for index, relate_rate in enumerate(relates_words_index):\n",
    "\n",
    "    if (relate_rate > .2):\n",
    "        #print(index)\n",
    "        print(txt_dict['text'][index])"
   ]
  },
  {
   "source": [
    "## Filter loss run report from others ##\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_txt = './data/txt/'\n",
    "path_im = './data/images/'\n",
    "_file = '2015 09 loss Professional Liab WIL-NO'\n",
    "loss_2 = lossrun.read_dict(path_txt + _file + '.txt')\n",
    "plt.figure(figsize=(20,20))\n",
    "image  = cv2.imread(path_im + _file + '.png')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_text = []\n",
    "txt_y, txt_x = [],[]\n",
    "\n",
    "for i  in range(len(loss_2['text'])):\n",
    "\n",
    "    if loss_2['text'][i]!= '':\n",
    "\n",
    "        only_text.append(loss_2['width'][i] * loss_2['height'][i])\n",
    "        txt_x.append(loss_2['left'][i])\n",
    "        txt_y.append(loss_2['top'][i]) \n",
    "        \n",
    "# densidad general del texto \n",
    "altura = max(txt_y) - min(txt_y)\n",
    "base = max(txt_x) - min(txt_x)\n",
    "\n",
    "# densidad por palabra\n",
    "x = sum(only_text)\n",
    "\n",
    "sum(only_text) / (altura * base) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probar la distribución del text \n",
    "# centro de masa del texto\n",
    "# similitd de texo \n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "loss_1 = lossrun.read_dict(path_txt +  'Email from Ashley to decline due to losses'+ '.txt')\n",
    "loss_1 = ' '.join(loss_1['text'])\n",
    "\n",
    "loss_2 = lossrun.read_dict(path_txt + 'AHC-0000343 loss runs PIO-YES' + '.txt')\n",
    "loss_2 = ' '.join(loss_2['text'])\n",
    "\n",
    "loss_3 = lossrun.read_dict(path_txt + 'madison medical llc loss runs VGM-NO' + '.txt')\n",
    "loss_3 = ' '.join(loss_3['text'])\n",
    "\n",
    "\n",
    "string_1 = nlp(loss_1)\n",
    "string_2 = nlp(loss_2)\n",
    "string_3 = nlp(loss_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_2.similarity(string_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6801620074936275 Insured\n0.30641449276149085 Division\n0.2469806626816359 Master/Subsidiary\n0.03149815656929901 BCO\n0.4265783115031161 Claim\n0.14402429732187544 Sub\n-0.05077370131100734 Ltr]\n0.36892557986386465 Valuation\n0.20842582224512837 Number\n0.0 G2717131A\n0.4060020539406819 Policy\n0.2707394799946922 Term\n0.0 10/28/2013\n-0.0320739006781649 -\n0.0 09/01/2014\n0.4060020539406819 Policy\n0.20842582224512837 Number\n0.0 G2717131A\n0.4060020539406819 Policy\n0.2707394799946922 Term\n0.0 09/01/2014\n-0.0320739006781649 -\n0.0 09/01/2015\n"
     ]
    }
   ],
   "source": [
    "sent = 'Insured Division Master/Subsidiary BCO Claim Sub Ltr] Valuation Number G2717131A Policy Term 10/28/2013 - 09/01/2014 Policy Number G2717131A Policy Term 09/01/2014 - 09/01/2015'\n",
    "\n",
    "entity = nlp('insurer')\n",
    "\n",
    "for i in sent.split():\n",
    "    doc = nlp (i)\n",
    "    print(entity.similarity(doc) , i)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}