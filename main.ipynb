{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Insurance Loss Runs #\n",
    "## automatic extraction of relevant information in loss reports from pdf files ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-10-13 10:05:13,056 INFO sqlalchemy.engine.base.Engine select version()\n",
      "2020-10-13 10:05:13,057 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-13 10:05:13,063 INFO sqlalchemy.engine.base.Engine select current_schema()\n",
      "2020-10-13 10:05:13,064 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-13 10:05:13,066 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-10-13 10:05:13,066 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-13 10:05:13,068 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-10-13 10:05:13,069 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-13 10:05:13,069 INFO sqlalchemy.engine.base.Engine show standard_conforming_strings\n",
      "2020-10-13 10:05:13,070 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-10-13 10:05:13,072 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-13 10:05:13,073 INFO sqlalchemy.engine.base.Engine {'name': 'time_dim'}\n",
      "2020-10-13 10:05:13,075 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-13 10:05:13,076 INFO sqlalchemy.engine.base.Engine {'name': 'status_dim'}\n",
      "2020-10-13 10:05:13,078 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-13 10:05:13,078 INFO sqlalchemy.engine.base.Engine {'name': 'insurer_dim'}\n",
      "2020-10-13 10:05:13,080 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-13 10:05:13,080 INFO sqlalchemy.engine.base.Engine {'name': 'insured_dim'}\n",
      "2020-10-13 10:05:13,082 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-13 10:05:13,082 INFO sqlalchemy.engine.base.Engine {'name': 'policy_dim'}\n",
      "2020-10-13 10:05:13,084 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-13 10:05:13,084 INFO sqlalchemy.engine.base.Engine {'name': 'lossrunreport_dim'}\n",
      "2020-10-13 10:05:13,086 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-13 10:05:13,087 INFO sqlalchemy.engine.base.Engine {'name': 'reportgenerator_dim'}\n",
      "2020-10-13 10:05:13,088 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2020-10-13 10:05:13,089 INFO sqlalchemy.engine.base.Engine {'name': 'lossrun_fact'}\n",
      "2020-10-13 10:05:13,099 INFO sqlalchemy.engine.base.Engine BEGIN (implicit)\n",
      "2020-10-13 10:05:13,101 INFO sqlalchemy.engine.base.Engine INSERT INTO time_dim (day, month, year) VALUES (%(day)s, %(month)s, %(year)s) RETURNING time_dim.timeid\n",
      "2020-10-13 10:05:13,101 INFO sqlalchemy.engine.base.Engine {'day': 5, 'month': 12, 'year': None}\n",
      "2020-10-13 10:05:13,104 INFO sqlalchemy.engine.base.Engine INSERT INTO status_dim (status_name) VALUES (%(status_name)s) RETURNING status_dim.status_id\n",
      "2020-10-13 10:05:13,104 INFO sqlalchemy.engine.base.Engine {'status_name': 'Test'}\n",
      "2020-10-13 10:05:13,107 INFO sqlalchemy.engine.base.Engine INSERT INTO lossrun_fact (loss_date, policy_id, loss_reported_date, claim_reference, status_id, claimant_name, expense_reserve, indemnity_reserve, expense_paid, indemnity_paid, total_incurred, lossrunreport_id, reportgenerator_id, insurer_id, insured_id) VALUES (%(loss_date)s, %(policy_id)s, %(loss_reported_date)s, %(claim_reference)s, %(status_id)s, %(claimant_name)s, %(expense_reserve)s, %(indemnity_reserve)s, %(expense_paid)s, %(indemnity_paid)s, %(total_incurred)s, %(lossrunreport_id)s, %(reportgenerator_id)s, %(insurer_id)s, %(insured_id)s) RETURNING lossrun_fact.fact_id\n",
      "2020-10-13 10:05:13,108 INFO sqlalchemy.engine.base.Engine {'loss_date': 92, 'policy_id': None, 'loss_reported_date': 92, 'claim_reference': None, 'status_id': 92, 'claimant_name': None, 'expense_reserve': None, 'indemnity_reserve': None, 'expense_paid': None, 'indemnity_paid': None, 'total_incurred': None, 'lossrunreport_id': None, 'reportgenerator_id': None, 'insurer_id': None, 'insured_id': None}\n",
      "2020-10-13 10:05:13,110 INFO sqlalchemy.engine.base.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "## load depedencies \n",
    "import lossrun\n",
    "import lossrun_models # ORM models\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Run this to update the pdf files to process\n",
    "\n",
    "lossrun.transform_to_images_an_entire_folder(pdfs_folder='./data/pdfs/', images_folder='./data/images/', format='.png', log_file='log_file.txt')\n",
    "\n",
    "lossrun.transform_to_text_an_entire_folder(images_folder='./data/images/', text_folder= './data/txt/', log_file='log_file.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./data/images/2015 09 loss Professional Liab WIL-NO.jpg\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-60c212989994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Orignial data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;31m# Orignial data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2706\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m         data=None, **kwargs):\n\u001b[0;32m-> 2708\u001b[0;31m     __ret = gca().imshow(\n\u001b[0m\u001b[1;32m   2709\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5521\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5523\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5524\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    694\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[1;32m    695\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[0;32m--> 696\u001b[0;31m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0m\u001b[1;32m    697\u001b[0m                             \"float\".format(self._A.dtype))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    }
   ],
   "source": [
    "## Select file\n",
    "\n",
    "\n",
    "# pdf raw file no ext \n",
    "#__________________________________________\n",
    "#pdf_file = 'B00319X_Dr. Majoch loss run MAG-YES0'\n",
    "#___________________________________________\n",
    "\n",
    "#__________________________________________\n",
    "#pdf_file = 'AHC-0000343 loss runs PIO-YES0'\n",
    "#___________________________________________\n",
    "#....................................................\n",
    "\n",
    "#__________________________________________\n",
    "#pdf_file = '2015-16 PKG loss run CHU-NO'\n",
    "#___________________________________________\n",
    "\n",
    "\n",
    "#__________________________________________\n",
    "#pdf_file = 'Admiral LRs0'\n",
    "#___________________________________________\n",
    "#\n",
    "#___________________________________________\n",
    "pdf_file = '2015 09 loss Professional Liab WIL-NO'\n",
    "#__________________________________________\n",
    "\n",
    "\n",
    "# topic files\n",
    "topic_file = './data/configuration/config_topics_beta.ino'\n",
    "\n",
    "# Pre proc datapre_proc\n",
    "txt_dict, topics, image, image_c = lossrun.pre_proc(pdf_file, 'data', topic_file)\n",
    "\n",
    "# vizualizate data\n",
    "plt.figure(figsize=(23,20))\n",
    "# Orignial data\n",
    "plt.imshow(image)\n",
    "# Orignial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0692b8606f74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/images/2015 09 loss Professional Liab WIL-NO.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "\n",
    "x = cv2.imread('./data/images/2015 09 loss Professional Liab WIL-NO.jpg')\n",
    "#               ./data/images/2015 09 loss Professional Liab WIL-NO.png\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial relation filter ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "policy_num 108 160  Insured Division Master/Subsidiary BCO Claim Sub Ltr] Valuation Number G2717131A Policy Term 10/28/2013 - 09/01/2014 Policy Number G2717131A Policy Term 09/01/2014 - 09/01/2015\n Insured Division Master/Subsidiary BCO Claim Sub Ltr] Valuation Number G2717131A Policy Term 10/28/2013 - 09/01/2014 Policy Number G2717131A Policy Term 09/01/2014 - 09/01/2015\n....................................................................................................\n\npolicy_num 2309 160  Insured Division Master/Subsidiary BCO Claim Sub Ltr] Valuation Number G2717131A Policy Term 09/01/2014 - 09/01/2015\n Insured Division Master/Subsidiary BCO Claim Sub Ltr] Valuation Number G2717131A Policy Term 09/01/2014 - 09/01/2015\n....................................................................................................\n\npolicy_num 1208 160 PAC |MCC Claimant Term 10/28/2013 - 09/01/2014 Policy Number G2717131A Policy Term 09/01/2014 - 09/01/2015\nPAC |MCC Claimant Term 10/28/2013 - 09/01/2014 Policy Number G2717131A Policy Term 09/01/2014 - 09/01/2015\n....................................................................................................\n\npolicy_num 3409 160 PAC |MCC Claimant Term 09/01/2014 - 09/01/2015\nPAC |MCC Claimant Term 09/01/2014 - 09/01/2015\n....................................................................................................\n\ninsured 108 200  Division Master/Subsidiary BCO Claim Sub Ltr] Valuation Name Breathe Technologies Insured Name Breathe Technologies\n Division Master/Subsidiary BCO Claim Sub Ltr] Valuation Name Breathe Technologies Insured Name Breathe Technologies\n....................................................................................................\n\ninsured 2309 200  Division Master/Subsidiary BCO Claim Sub Ltr] Valuation Name Breathe Technologies\n Division Master/Subsidiary BCO Claim Sub Ltr] Valuation Name Breathe Technologies\n....................................................................................................\n\nstatus 1390 498  Subtotal ‘ Gross Paid Gross Incurred |Gross Paid Loss Expenses Outstanding Loss Made Report Close Reopen ‘ ‘ Gross Paid Gross Incurred Sub Ltr] Occurrence ID AIM Date Date Date Date Date State Desc Claimant Status |Gross Paid Loss Expenses Outstanding Loss\n Subtotal ‘ Gross Paid Gross Incurred |Gross Paid Loss Expenses Outstanding Loss Made Report Close Reopen ‘ ‘ Gross Paid Gross Incurred Sub Ltr] Occurrence ID AIM Date Date Date Date Date State Desc Claimant Status |Gross Paid Loss Expenses Outstanding Loss\n....................................................................................................\n\nstatus 3591 498  Subtotal Grand Total ‘ Gross Paid Gross Incurred |Gross Paid Loss Expenses Outstanding Loss\n Subtotal Grand Total ‘ Gross Paid Gross Incurred |Gross Paid Loss Expenses Outstanding Loss\n....................................................................................................\n\n"
     ]
    }
   ],
   "source": [
    "spatial_filter = lossrun.spatial_filter(txt_dict, topics)\n",
    "spatial_filter_topics = len(spatial_filter)\n",
    "\n",
    "for topic in range(spatial_filter_topics):\n",
    "\n",
    "    string = ' '.join(spatial_filter[topic])\n",
    "    string = re.sub('\\s+',' ', string)\n",
    "    print(topics[topic][0] + ' ' + str(topics[topic][3]) + ' ' +str(topics[topic][4]) +' ' + string)\n",
    "    print(string )\n",
    "    print('.'*100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name entity recognition ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD NAME MODEL \n",
    "import spacy \n",
    "nlp = spacy.load('./data/results/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from configobj import ConfigObj\n",
    "import string as String\n",
    "printable = set(String.printable)\n",
    "# topic rules\n",
    "ner_rules = ConfigObj('./data/configuration/config_rules_beta.ino')\n",
    "\n",
    "_temp = []\n",
    "#\n",
    "for i in range(len(spatial_filter)):\n",
    "\n",
    "    string = ' '.join(spatial_filter[:][i])\n",
    "    string = re.sub('\\s+',' ',string)\n",
    "    \n",
    "    \n",
    "    # remove non printalbes elemts\n",
    "    string = ''.join(filter(lambda x: x in printable, string))\n",
    "    #print (string)\n",
    "    doc = nlp(string)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        print('It will be added to data base : ')\n",
    "        print(ent.text + ' in ' + ent.label_)\n",
    "        print('\\n.................')\n",
    "        \n"
   ]
  },
  {
   "source": [
    "## DATA BASE INSERTION ##"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Sinlge function for database insertion\n",
    "Lossrun_models.registerRecord(timeDimDay = 12,\n",
    "                              timeDimMonth = 9,\n",
    "                              timeDimYear = 20,\n",
    "                              policyDimStatus = \"Open\", \n",
    "                              reportGeneratorDimName = _temp[encuentra(_temp,'ORG')][0], \n",
    "                              insuredDimName = _temp[encuentra(_temp,'ORG')][0],\n",
    "                              insurerDimName = _temp[encuentra(_temp,'PERSON')][0], \n",
    "                              statusName = \"Open\", \n",
    "                              lossRunReportDimDate = datetime.datetime.now()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model \n",
    "model = lossrun.load_context_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar('carrier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = []\n",
    "try:\n",
    "    similar.append(model.most_similar_to_given('ORG', txt_dict['text']))\n",
    "except: \n",
    "    similar.append('0')\n",
    "\n",
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test cell ignore it\n",
    "###############################\n",
    "\n",
    "\n",
    "# check topic\n",
    "_topic = 'Paid'\n",
    "\n",
    "relates_words_index = []\n",
    "\n",
    "rate_relation =  0.1 # where grammar  correlation goes to -1 to 1 \n",
    "\n",
    "for i in txt_dict['text']:\n",
    "\n",
    "    try:\n",
    "        relates_words_index.append(model.similarity(_topic, i))\n",
    "    except:\n",
    "        relates_words_index.append(0)\n",
    "#model.similarity()\n",
    "for index, relate_rate in enumerate(relates_words_index):\n",
    "\n",
    "    if (relate_rate > .2):\n",
    "        #print(index)\n",
    "        print(txt_dict['text'][index])"
   ]
  },
  {
   "source": [
    "## Filter loss run report from others ##\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_txt = './data/txt/'\n",
    "path_im = './data/images/'\n",
    "_file = '2015 09 loss Professional Liab WIL-NO'\n",
    "loss_2 = lossrun.read_dict(path_txt + _file + '.txt')\n",
    "plt.figure(figsize=(20,20))\n",
    "image  = cv2.imread(path_im + _file + '.png')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_text = []\n",
    "txt_y, txt_x = [],[]\n",
    "\n",
    "for i  in range(len(loss_2['text'])):\n",
    "\n",
    "    if loss_2['text'][i]!= '':\n",
    "\n",
    "        only_text.append(loss_2['width'][i] * loss_2['height'][i])\n",
    "        txt_x.append(loss_2['left'][i])\n",
    "        txt_y.append(loss_2['top'][i]) \n",
    "        \n",
    "# densidad general del texto \n",
    "altura = max(txt_y) - min(txt_y)\n",
    "base = max(txt_x) - min(txt_x)\n",
    "\n",
    "# densidad por palabra\n",
    "x = sum(only_text)\n",
    "\n",
    "sum(only_text) / (altura * base) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probar la distribución del text \n",
    "# centro de masa del texto\n",
    "# similitd de texo \n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "loss_1 = lossrun.read_dict(path_txt +  'Email from Ashley to decline due to losses'+ '.txt')\n",
    "loss_1 = ' '.join(loss_1['text'])\n",
    "\n",
    "loss_2 = lossrun.read_dict(path_txt + 'AHC-0000343 loss runs PIO-YES' + '.txt')\n",
    "loss_2 = ' '.join(loss_2['text'])\n",
    "\n",
    "loss_3 = lossrun.read_dict(path_txt + 'madison medical llc loss runs VGM-NO' + '.txt')\n",
    "loss_3 = ' '.join(loss_3['text'])\n",
    "\n",
    "\n",
    "string_1 = nlp(loss_1)\n",
    "string_2 = nlp(loss_2)\n",
    "string_3 = nlp(loss_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_2.similarity(string_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6801620074936275 Insured\n0.30641449276149085 Division\n0.2469806626816359 Master/Subsidiary\n0.03149815656929901 BCO\n0.4265783115031161 Claim\n0.14402429732187544 Sub\n-0.05077370131100734 Ltr]\n0.36892557986386465 Valuation\n0.20842582224512837 Number\n0.0 G2717131A\n0.4060020539406819 Policy\n0.2707394799946922 Term\n0.0 10/28/2013\n-0.0320739006781649 -\n0.0 09/01/2014\n0.4060020539406819 Policy\n0.20842582224512837 Number\n0.0 G2717131A\n0.4060020539406819 Policy\n0.2707394799946922 Term\n0.0 09/01/2014\n-0.0320739006781649 -\n0.0 09/01/2015\n"
     ]
    }
   ],
   "source": [
    "sent = 'Insured Division Master/Subsidiary BCO Claim Sub Ltr] Valuation Number G2717131A Policy Term 10/28/2013 - 09/01/2014 Policy Number G2717131A Policy Term 09/01/2014 - 09/01/2015'\n",
    "\n",
    "entity = nlp('insurer')\n",
    "\n",
    "for i in sent.split():\n",
    "    doc = nlp (i)\n",
    "    print(entity.similarity(doc) , i)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}